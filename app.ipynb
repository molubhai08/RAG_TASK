{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de28d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tiktoken\n",
    "import statistics\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "495f7b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pages loaded: 34\n",
      "Company Policies \n",
      "Company Name: NovaCart Technologies Pvt. Ltd. \n",
      "Corporate Office: [Address to be added] \n",
      "Customer Support Email: support@novacart.com \n",
      "Customer Support Phone: +91-XXXX-XXXXXX \n",
      "Website: www.novacart.com \n",
      "Last Updated: January 2026 \n",
      "Effective Date: January 1, 2026 \n",
      " \n",
      "Table of Contents \n",
      "1. Refund Policy \n",
      "2. Cancellation Policy \n",
      "3. Shipping Policy \n",
      "4. Exchange Policy \n",
      "5. Product Warranty Policy \n",
      "6. Customer Support \n",
      "7. Privacy and Data Protection \n",
      "8. Terms and Conditions \n",
      "9. Dispute Resolution \n",
      "10. Policy Limitations and Updates \n",
      " \n",
      "1. Refund Policy \n",
      "1.1 Eligibility for Refunds \n",
      "Customers may request a full refund for eligible products within 14 calendar days from the date of \n",
      "delivery. The refund window begins on the day the product is delivered to the customer's registered \n",
      "address. \n",
      "Conditions for Refund Eligibility \n",
      "To qualify for a refund, all of the following conditions must be met: \n",
      "• Unused Condition: The product must be completely unused, unworn, and show no signs \n"
     ]
    }
   ],
   "source": [
    "pdf_path = \"Company Policies.pdf\"\n",
    "\n",
    "loader = PyPDFLoader(pdf_path)\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Total pages loaded: {len(documents)}\")\n",
    "print(documents[0].page_content[:1000])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e50124d7",
   "metadata": {},
   "source": [
    "Document Specific Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd81d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total policy sections found: 11\n"
     ]
    }
   ],
   "source": [
    "full_text = \"\\n\".join(doc.page_content for doc in documents)\n",
    "\n",
    "import re\n",
    "\n",
    "SECTION_REGEX = re.compile(\n",
    "    r\"\\n(?=\\d+\\.\\s+[A-Z][A-Za-z\\s]+Policy)\"\n",
    ")\n",
    "\n",
    "sections = re.split(SECTION_REGEX, full_text)\n",
    "\n",
    "print(f\"Total policy sections found: {len(sections)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9db85365",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable policy sections: 6\n"
     ]
    }
   ],
   "source": [
    "section_docs = []\n",
    "\n",
    "for section in sections:\n",
    "    cleaned = section.strip()\n",
    "    if len(cleaned) > 200:  # ignore junk\n",
    "        section_docs.append(\n",
    "            Document(\n",
    "                page_content=cleaned,\n",
    "                metadata={\"source\": \"company_policies\"}\n",
    "            )\n",
    "        )\n",
    "\n",
    "print(f\"Usable policy sections: {len(section_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36363de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "def count_tokens(text: str) -> int:\n",
    "    return len(encoding.encode(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d167c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Section token stats:\n",
      "Min: 78\n",
      "Avg: 1513\n",
      "Median: 1496\n",
      "75th percentile: 2101\n",
      "Max: 3238\n"
     ]
    }
   ],
   "source": [
    "section_token_sizes = [count_tokens(doc.page_content) for doc in section_docs]\n",
    "\n",
    "print(\"Section token stats:\")\n",
    "print(\"Min:\", min(section_token_sizes))\n",
    "print(\"Avg:\", round(statistics.mean(section_token_sizes)))\n",
    "print(\"Median:\", round(statistics.median(section_token_sizes)))\n",
    "print(\"75th percentile:\", round(statistics.quantiles(section_token_sizes, n=4)[2]))\n",
    "print(\"Max:\", max(section_token_sizes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3097fb37",
   "metadata": {},
   "source": [
    "Evaluating Chunk Size for Large Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd8ea47b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600, 120)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p75 = statistics.quantiles(section_token_sizes, n=4)[2]\n",
    "\n",
    "CHUNK_SIZE = min(round(p75), 600)\n",
    "CHUNK_OVERLAP = round(CHUNK_SIZE * 0.2)\n",
    "\n",
    "CHUNK_SIZE, CHUNK_OVERLAP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d933a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,        # 600\n",
    "    chunk_overlap=CHUNK_OVERLAP,  # 120\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0b115104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 90\n"
     ]
    }
   ],
   "source": [
    "chunked_docs = []\n",
    "\n",
    "for doc in section_docs:\n",
    "    token_count = count_tokens(doc.page_content)\n",
    "\n",
    "    if token_count <= CHUNK_SIZE:\n",
    "        # Keep small sections as-is\n",
    "        chunked_docs.append(doc)\n",
    "    else:\n",
    "        # Recursively split large sections\n",
    "        splits = text_splitter.split_text(doc.page_content)\n",
    "        for split in splits:\n",
    "            chunked_docs.append(\n",
    "                Document(\n",
    "                    page_content=split,\n",
    "                    metadata=doc.metadata\n",
    "                )\n",
    "            )\n",
    "\n",
    "print(f\"Total chunks created: {len(chunked_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15f2e3c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk size stats:\n",
      "Min: 46\n",
      "Avg: 120\n",
      "Max: 169\n"
     ]
    }
   ],
   "source": [
    "chunk_sizes = [count_tokens(doc.page_content) for doc in chunked_docs]\n",
    "\n",
    "print(\"Chunk size stats:\")\n",
    "print(\"Min:\", min(chunk_sizes))\n",
    "print(\"Avg:\", round(statistics.mean(chunk_sizes)))\n",
    "print(\"Max:\", max(chunk_sizes))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce70dc1",
   "metadata": {},
   "source": [
    "Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39536393",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SARTHAK\\AppData\\Local\\Temp\\ipykernel_23708\\328479181.py:3: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the `langchain-huggingface package and should be used instead. To use it run `pip install -U `langchain-huggingface` and import as `from `langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={\"normalize_embeddings\": True}  # important for cosine similarity\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9488155b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total vectors stored: 90\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "\n",
    "vectorstore = FAISS.from_documents(\n",
    "    documents=chunked_docs,\n",
    "    embedding=embedding_model\n",
    ")\n",
    "\n",
    "print(\"Total vectors stored:\", vectorstore.index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a59d9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03605084",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.0  # critical for hallucination control\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c55b5f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETRIEVAL_K = 5\n",
    "RELATIVE_THRESHOLD = 0.6   # keep chunks close to the best one\n",
    "MIN_SCORE_FLOOR = 0.2      # safety floor to avoid junk retrievals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ad227a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_with_gating(query: str):\n",
    "    results = vectorstore.similarity_search_with_score(\n",
    "        query,\n",
    "        k=RETRIEVAL_K\n",
    "    )\n",
    "\n",
    "    if not results:\n",
    "        return []\n",
    "\n",
    "    best_score = results[0][1]\n",
    "\n",
    "    # If even the best result is weak, refuse early\n",
    "    if best_score < MIN_SCORE_FLOOR:\n",
    "        return []\n",
    "\n",
    "    filtered = [\n",
    "        (doc, score)\n",
    "        for doc, score in results\n",
    "        if score >= best_score * RELATIVE_THRESHOLD\n",
    "    ]\n",
    "\n",
    "    return filtered\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a4b017f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f019855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=\"\"\"\n",
    "You are a policy question-answering assistant.\n",
    "\n",
    "Rules (must be followed strictly):\n",
    "1. Answer using ONLY the information provided in the Context.\n",
    "2. If the Context contains partial information, answer using only what is stated and clearly\n",
    "   mention any missing details.\n",
    "3. If the Context contains no relevant information, say:\n",
    "   \"I cannot answer this question based on the provided documents.\"\n",
    "4. Do NOT use prior knowledge.\n",
    "5. Do NOT guess or infer beyond the text.\n",
    "6. Be concise, factual, and neutral.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\n",
    "\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "49bf0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "REFUSAL = \"I cannot answer this question based on the provided documents.\"\n",
    "\n",
    "def rag_answer(query: str):\n",
    "    retrieved = retrieve_with_gating(query)\n",
    "\n",
    "    if not retrieved:\n",
    "        return REFUSAL\n",
    "\n",
    "    context_blocks = []\n",
    "    for doc, score in retrieved:\n",
    "        context_blocks.append(\n",
    "            f\"[Relevance Score: {round(score, 2)}]\\n{doc.page_content}\"\n",
    "        )\n",
    "\n",
    "    context = \"\\n\\n---\\n\\n\".join(context_blocks)\n",
    "\n",
    "    prompt = rag_prompt.format(\n",
    "        context=context,\n",
    "        question=query\n",
    "    )\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf624b5",
   "metadata": {},
   "source": [
    "Easy Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "db808a44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The delivery timelines for express and standard shipping in the Asia-Pacific region are: \n",
      "• Express: 3-5 business days \n",
      "• Standard: 7-10 business days\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_answer(\"What are the delivery timelines for express and standard shipping in the Asia-Pacific region\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd121dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, same-day delivery is available as a pilot program in select metro areas, but it has certain conditions: \n",
      "- The order must be placed before 12 PM.\n",
      "- It is limited to specific product categories.\n",
      "- Additional charges of ₹150-500 apply.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_answer(\"Do you offer same-day delivery?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da60ead0",
   "metadata": {},
   "source": [
    "Some partially answerable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0872c84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided Context, the factors that can delay international shipping orders are:\n",
      "\n",
      "1. Customs Clearance: International orders (typically 1-5 days)\n",
      "2. Courier Delays: Third-party logistics partner delays\n",
      "3. Address Issues: Incomplete or incorrect delivery information\n",
      "4. High Demand Periods: Sale events, festive seasons\n",
      "5. COVID-19 or Health Emergencies: Lockdowns, movement restrictions\n",
      "6. Remote Locations: Accessibility and infrastructure challenges\n",
      "7. Natural Disasters: Floods, earthquakes, cyclones \n",
      "\n",
      "Additionally, customs delays can occur if customers do not provide accurate product information for customs declaration, do not respond promptly to customs queries, or do not pay applicable duties to release shipment.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_answer(\"What factors can delay international shipping orders?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0d9873f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For customers in remote locations, delivery is available through partnered courier services. However, it may require additional shipping charges (₹50-150) and the delivery timeline is 7-10 business days. Additionally, some products may not be eligible for delivery in these areas.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_answer(\"What delivery options are available for customers in remote locations?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83d6b63",
   "metadata": {},
   "source": [
    "Some unanswerable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a332943a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question based on the provided documents. The Context mentions that same-day delivery is available in \"select metro areas\", but it does not specify which metro cities are included in the pilot program.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_answer(\"Which metro cities are included in the same-day delivery pilot program?\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "86738396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I cannot answer this question based on the provided documents.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    rag_answer(\"Does NovaCart offer carbon-neutral or eco-friendly shipping options?\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
